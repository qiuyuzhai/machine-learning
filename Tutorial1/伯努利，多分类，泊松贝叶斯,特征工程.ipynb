{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "# 从numpy库导入所有函数和类（不推荐在实际项目中使用这种方式）\n",
    "from numpy import *\n",
    "\n",
    "# 从sklearn（scikit-learn）库导入所有函数和类（不推荐在实际项目中使用这种方式）\n",
    "from sklearn import *\n",
    "\n",
    "# 从scipy库导入stats（统计函数）和special（特殊数学函数）模块，是Numpy的高级版\n",
    "from scipy import stats, special\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取文本数据集\n",
    "\n",
    "removeset = ('headers', 'footers', 'quotes') # 移除标题、页脚和引用内容\n",
    "\n",
    "# 定义我们只使用的4个新闻类别\n",
    "cats      = ['alt.atheism',         # 关于无神论\n",
    "             'talk.religion.misc',  # 关于宗教\n",
    "             'comp.graphics',       # 关于计算机图形学\n",
    "             'sci.space']           # 关于太空科学\n",
    "\n",
    "# 加载训练数据集\n",
    "# subset='train' 表示加载训练集\n",
    "# remove=removeset 表示移除指定的内容（标题、页脚、引用）\n",
    "# categories=cats 表示只加载指定的4个类别\n",
    "# data_home='./' 表示数据存储在当前目录下\n",
    "newsgroups_train = datasets.fetch_20newsgroups(subset='train',\n",
    "                           remove=removeset, categories=cats, data_home='./')\n",
    "\n",
    "\n",
    "newsgroups_test  = datasets.fetch_20newsgroups(subset='test', \n",
    "                           remove=removeset, categories=cats, data_home='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据\n",
    "traindata = newsgroups_train.data\n",
    "trainY = newsgroups_train.target\n",
    "testdata = newsgroups_test.data\n",
    "testY  = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本是 “非结构化数据”，需要先转换为模型可理解的 “结构化数值特征”（词汇表是实现这一转换的核心工具之一）。\n",
    "from sklearn import feature_extraction\n",
    "# BoW词汇表\n",
    "cntvect = feature_extraction.text.CountVectorizer(stop_words='english', max_features=100)\n",
    "trainX = cntvect.fit_transform(traindata)\n",
    "testX  = cntvect.transform(testdata)\n",
    "\n",
    "# 查看特征形状\n",
    "print(f\"训练集特征形状: {trainX.shape}\")\n",
    "print(f\"测试集特征形状: {testX.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 朴素伯努利贝叶斯\n",
    "# 用伯努利是因为文本特征是0/1二值型的\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "bmodel=BernoulliNB()\n",
    "#bnb.fit接受（二维矩阵，一维数组）\n",
    "bmodel.fit(trainX,trainY)\n",
    "testY_pred=bmodel.predict(testX)\n",
    "accuracy=accuracy_score(testY,testY_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多项式朴素贝叶斯\n",
    "# 用多项式是因为文本特征是计数型的\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mmodel = MultinomialNB()\n",
    "mmodel.fit(trainX, trainY)\n",
    "predY= mmodel.predict(testX)\n",
    "accuracy=accuracy_score(testY,predY)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9574e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成TF-IDF特征\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvect = TfidfVectorizer(\n",
    "    stop_words='english', \n",
    "    max_features=100\n",
    ")\n",
    "trainX_tf= tfidfvect.fit_transform(traindata)  # 训练集TF-IDF特征\n",
    "testX_tf = tfidfvect.transform(testdata)        # 测试集TF-IDF特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "mmodel_tf = MultinomialNB()\n",
    "mmodel_tf.fit(trainX_tf, trainY)\n",
    "predY_tf = mmodel_tf.predict(testX_tf)\n",
    "accuracy=accuracy_score(testY,predY_tf)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1144769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 泊松朴素贝叶斯\n",
    "from scipy.stats import poisson\n",
    "from scipy.special import logsumexp\n",
    "import numpy as np\n",
    "\n",
    "class PoissonBayes:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # 获取唯一类别数量\n",
    "        self.K = len(np.unique(y))\n",
    "        self.mu = []       # 存储每个类别每个特征的均值\n",
    "        self.pi = []       # 存储先验概率\n",
    "        \n",
    "        for c in range(self.K):\n",
    "            # 筛选出属于当前类别c的所有样本\n",
    "            # 注意：X是稀疏矩阵，需要转换为数组才能正确计算均值\n",
    "            Xc = X[y == c].toarray() if hasattr(X, 'toarray') else X[y == c]\n",
    "            # 计算每个特征的均值（按列计算）\n",
    "            self.mu.append(np.mean(Xc, axis=0))\n",
    "            # 计算先验概率\n",
    "            self.pi.append(np.mean(y == c))\n",
    "        \n",
    "        self.pi = np.array(self.pi)\n",
    "\n",
    "    # 计算类别c的类条件概率log p(x|y=c)的对数\n",
    "    def compute_logccd(self, X, c):\n",
    "        # 将稀疏矩阵转换为数组以便处理\n",
    "        if hasattr(X, 'toarray'):\n",
    "            X = X.toarray()\n",
    "            \n",
    "        lx = []\n",
    "        # 获取当前类别的均值数组\n",
    "        mu_c = self.mu[c]\n",
    "        for i in range(X.shape[1]):\n",
    "            # 获取单个特征的均值（标量）\n",
    "            mu_ic = mu_c[i]\n",
    "            # 获取单个特征的所有样本值\n",
    "            x_i = X[:, i]\n",
    "            \n",
    "            # 处理均值为零的情况\n",
    "            if mu_ic == 0:\n",
    "                # 如果均值为零，只有当x_i为零时概率才为1\n",
    "                log_p = np.where(x_i == 0, 0, -np.inf)\n",
    "            else:\n",
    "                # 计算泊松分布的对数概率密度\n",
    "                log_p = poisson.logpmf(x_i, mu_ic)\n",
    "                \n",
    "            lx.append(log_p)\n",
    "        \n",
    "        # 对所有特征的对数概率求和\n",
    "        return np.sum(lx, axis=0)\n",
    "    \n",
    "    # 计算联合似然/概率的对数: log p(x,y=c) = log p(x|y=c) + log p(y=c)\n",
    "    # 即贝叶斯定理公式右侧的分子（联合概率）\n",
    "    def compute_logjoint(self, X):\n",
    "        jl = [] # 列表：每个元素是一个长度为 “样本数” 的数组（对应一个类别的联合对数概率）\n",
    "        for c in range(self.K):\n",
    "            jl.append(self.compute_logccd(X, c) + np.log(self.pi[c]))\n",
    "        p = np.stack(jl, axis=-1)#axis=-1即多维数组里最后那一列\n",
    "        #p[i, c] 表示第 i 个样本属于类别 c 的联合对数概率，即log(p(xi|y=c))\n",
    "        return p\n",
    "    \n",
    "    # 计算每个类别给定X的后验对数概率 log p(y|x)\n",
    "    def predict_logproba(self, X):\n",
    "        # 计算联合对数似然 log p(x,y)\n",
    "        lp = self.compute_logjoint(X)\n",
    "        \n",
    "        # 计算log p(x) = log （所有类别的联合概率之和）\n",
    "        lpx = logsumexp(lp, axis=1)\n",
    "        \n",
    "        # 后验对数概率公式: log p(y|x) = log p(x,y) - log p(x)\n",
    "        # lpx[:, np.newaxis]用于维度扩展，使广播运算成立\n",
    "        # 广播运算：让形状不一样但 “兼容” 的数组，能自动调整成相同维度后再做计算\n",
    "        return lp - lpx[:, np.newaxis]\n",
    "    \n",
    "    # 计算每个类别给定x的后验概率 p(y|x)\n",
    "    def predict_proba(self, X):\n",
    "        # 对后验对数概率取指数，转换为概率值\n",
    "        return np.exp(self.predict_logproba(X))\n",
    "    \n",
    "    # 预测x的最可能类别\n",
    "    def predict(self, X):\n",
    "        # 联合对数概率矩阵：[样本数, 类别数]，例如：[-2.1, -3.2, -1.8],  样本对类别0、1、2的联合对数概率\n",
    "        lp = self.compute_logjoint(X)\n",
    "        # argmax(lp, axis=1)沿行方向（每个样本）找最大值的索引\n",
    "        c = np.argmax(lp, axis=1)\n",
    "        \n",
    "        # 返回预测的类别标签\n",
    "        return c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35482d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnb=PoissonBayes()\n",
    "pnb.fit(trainX,trainY)\n",
    "predY = pnb.predict(testX)\n",
    "acc = metrics.accuracy_score(testY, predY)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
