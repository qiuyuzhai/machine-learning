{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEvkug6gGb-3"
   },
   "source": [
    "**姓名：** Zhai Qiuyu\n",
    "\n",
    "**EID：** qiuyuzhai2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNdGFsJfGb-5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib_inline   # setup output image format\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import os\n",
    "import zipfile\n",
    "import fnmatch\n",
    "random.seed(100)\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcmIeEF9Gb-6",
    "outputId": "9f6a2c53-4d07-4b83-c476-f4a2c85c6e40"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "print(\"Python:\", sys.version, \"PyTorch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z94aBLFcGb-6"
   },
   "source": [
    "## 1. 数据加载与预处理\n",
    "接下来我们需要加载图像。请下载 `faces.zip`，并将其放在与本 ipynb 文件相同的目录下。**不要解压**。然后运行下面的单元来加载图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4Azrj7JGb-7",
    "outputId": "2d8bb8db-476e-4e7c-f78c-eb8d8ab1298b"
   },
   "outputs": [],
   "source": [
    "imgdata = {'train':[], 'test':[]}\n",
    "classes = {'train':[], 'test':[]}\n",
    "\n",
    "# 数据集较大，因此对子集进行采样（subsample）以便更快加载和训练\n",
    "# 训练集下采样因子（每隔 train_subsample 个样本取 1 个；此处为 1 表示不下采样）\n",
    "train_subsample = 1\n",
    "train_counter = [0, 0]\n",
    "# 测试集中每个类别的最大样本数\n",
    "test_maxsample = 472\n",
    "test_counter = [0, 0]\n",
    "\n",
    "# 加载压缩包（请将 faces.zip 放在当前 ipynb 同目录下，无需解压）\n",
    "filename = 'faces.zip'\n",
    "zfile = zipfile.ZipFile(filename, 'r')\n",
    "\n",
    "for name in zfile.namelist():\n",
    "    # 筛选匹配的人脸图片路径：faces/<train|test>/<face|nonface>/<文件名>.png\n",
    "    if fnmatch.fnmatch(name, \"faces/*/*/*.png\"):\n",
    "\n",
    "        # 路径示例：faces/train/face/fname.png\n",
    "        (fdir1, fname)  = os.path.split(name)     # 提取文件名\n",
    "        (fdir2, fclass) = os.path.split(fdir1)    # 提取类别目录（face 或 nonface）\n",
    "        (fdir3, fset)   = os.path.split(fdir2)    # 提取数据集分割（train 或 test）\n",
    "        # 类别映射：1 = 人脸，0 = 非人脸\n",
    "        myclass = int(fclass == \"face\")\n",
    "\n",
    "        loadme = False\n",
    "        if fset == 'train':\n",
    "            # 训练集：按下采样因子选择是否加载\n",
    "            if (train_counter[myclass] % train_subsample) == 0:\n",
    "                loadme = True\n",
    "            train_counter[myclass] += 1\n",
    "        elif fset == 'test':\n",
    "            # 测试集：控制每类的最大样本量\n",
    "            if test_counter[myclass] < test_maxsample:\n",
    "                loadme = True\n",
    "            test_counter[myclass] += 1\n",
    "\n",
    "        if (loadme):\n",
    "            # 在内存中打开文件，并读取为灰度图像\n",
    "            myfile = zfile.open(name)\n",
    "            # img = matplotlib.image.imread(myfile)  # 另一种读取方式（保留参考）\n",
    "            img = skimage.io.imread(myfile, as_gray=True)\n",
    "            myfile.close()\n",
    "\n",
    "            # 追加图像与对应标签到数据列表\n",
    "            imgdata[fset].append(img)\n",
    "            classes[fset].append(myclass)\n",
    "\n",
    "\n",
    "zfile.close()\n",
    "imgsize = img.shape\n",
    "\n",
    "print(len(imgdata['train']))\n",
    "print(len(imgdata['test']))\n",
    "trainclass2start = sum(classes['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAZ8WSb0Gb-7"
   },
   "source": [
    "接下来我们将把图像列表转换为图像张量，以便于后续处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HpQkw-9HvQz",
    "outputId": "c05015b9-ea1d-4a6e-bc38-62d801bd698e"
   },
   "outputs": [],
   "source": [
    "# 将列表转换为 numpy 数组\n",
    "trainY = asarray(classes['train'])\n",
    "testY  = asarray(classes['test'])\n",
    "\n",
    "# 将类别标签转换为二值指示（one-hot 编码）\n",
    "trainYb_np = zeros((len(trainY), 2))\n",
    "trainYb_np[arange(len(trainY)), trainY] = 1\n",
    "testYb_np = zeros((len(testY), 2))\n",
    "testYb_np[arange(len(testY)), testY] = 1\n",
    "trainYb = F.one_hot(torch.tensor(trainY, dtype=torch.long), num_classes=2).float()\n",
    "testYb = F.one_hot(torch.tensor(testY, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "# 将 ndarray 列表转换为单个 ndarray（numpy 版本）\n",
    "trainI_np = asarray(imgdata['train']).reshape((6977,19,19,1))\n",
    "testI_np = asarray(imgdata['test']).reshape((944,19,19,1))\n",
    "trainI = torch.tensor(trainI_np, dtype=torch.float32).permute(0, 3, 1, 2)  # 将 NHWC 转为 NCHW\n",
    "testI = torch.tensor(testI_np, dtype=torch.float32).permute(0, 3, 1, 2)   # 将 NHWC 转为 NCHW\n",
    "\n",
    "# 清理内存\n",
    "del imgdata\n",
    "\n",
    "# 打乱数据（原始顺序按类别排列）\n",
    "random.seed(123)\n",
    "inds1 = random.permutation(len(trainI_np)).tolist()\n",
    "inds2 = random.permutation(len(testI_np)).tolist()\n",
    "trainYb = trainYb[inds1]\n",
    "testYb = testYb[inds2]\n",
    "trainY = trainY[inds1]\n",
    "testY = testY[inds2]\n",
    "trainI = trainI[inds1]\n",
    "testI = testI[inds2]\n",
    "\n",
    "print(trainI.shape)\n",
    "print(testI.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtPxJNMZGb-8"
   },
   "source": [
    "每幅图像是一个 19x19x1 的像素数组。最后一个维度表示图像的通道数——本例为灰度图像，因此只有 1 个通道。运行下面的代码以显示一个示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "GVhrvA0QGb-8",
    "outputId": "35a5add2-992b-4bed-bec9-b53c09f5b5ed"
   },
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(squeeze(trainI[1]), cmap='gray', interpolation='nearest')\n",
    "plt.title(\"face sample\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(squeeze(trainI[2]), cmap='gray', interpolation='nearest')\n",
    "plt.title(\"non-face sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OT_enx9Gb-8"
   },
   "source": [
    "运行下面的代码以显示更多图像！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "M1UHId__Gb-9",
    "outputId": "70cfbe2f-0a20-4cea-ed3a-bf1406e133b7"
   },
   "outputs": [],
   "source": [
    "# 显示图像\n",
    "\n",
    "# function to make an image montage\n",
    "def image_montage(X, imsize=None, maxw=10):\n",
    "    \"\"\"X can be a list of images, or a matrix of vectorized images.\n",
    "      Specify imsize when X is a matrix.\"\"\"\n",
    "    tmp = []\n",
    "    numimgs = len(X)\n",
    "\n",
    "    # create a list of images (reshape if necessary)\n",
    "    for i in range(0,numimgs):\n",
    "        if imsize != None:\n",
    "            tmp.append(X[i].reshape(imsize))\n",
    "        else:\n",
    "            tmp.append(squeeze(X[i]))\n",
    "\n",
    "    # add blanks\n",
    "    if (numimgs > maxw) and (mod(numimgs, maxw) > 0):\n",
    "        leftover = maxw - mod(numimgs, maxw)\n",
    "        meanimg = 0.5*(X[0].max()+X[0].min())\n",
    "        for i in range(0,leftover):\n",
    "            tmp.append(ones(tmp[0].shape)*meanimg)\n",
    "\n",
    "    # make the montage\n",
    "    tmp2 = []\n",
    "    for i in range(0,len(tmp),maxw):\n",
    "        tmp2.append( hstack(tmp[i:i+maxw]) )\n",
    "    montimg = vstack(tmp2)\n",
    "    return montimg\n",
    "\n",
    "# show images in a plot\n",
    "def show_imgs(W_list, nc=10, highlight_green=None, highlight_red=None, titles=None):\n",
    "    # nc is the number of columns\n",
    "    nfilter = len(W_list)\n",
    "    nr = (nfilter - 1) // nc + 1\n",
    "    for i in range(nr):\n",
    "        for j in range(nc):\n",
    "            idx = i * nc + j\n",
    "            if idx == nfilter:\n",
    "                break\n",
    "            plt.subplot(nr, nc, idx + 1)\n",
    "            cur_W = W_list[idx]\n",
    "            plt.imshow(cur_W,cmap='gray', interpolation='nearest')\n",
    "            if titles is not None:\n",
    "                if isinstance(titles, str):\n",
    "                    plt.title(titles.format(idx))\n",
    "                else:\n",
    "                    plt.title(titles[idx])\n",
    "\n",
    "            if ((highlight_green is not None) and highlight_green[idx]) or \\\n",
    "               ((highlight_red is not None) and highlight_red[idx]):\n",
    "                ax = plt.gca()\n",
    "                if highlight_green[idx]:\n",
    "                    mycol = '#00FF00'\n",
    "                else:\n",
    "                    mycol = 'r'\n",
    "                for S in ['bottom', 'top', 'right', 'left']:\n",
    "                    ax.spines[S].set_color(mycol)\n",
    "                    ax.spines[S].set_lw(2.0)\n",
    "                ax.xaxis.set_ticks_position('none')\n",
    "                ax.yaxis.set_ticks_position('none')\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "            else:\n",
    "                plt.gca().set_axis_off()\n",
    "\n",
    "# show a few images\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.imshow(image_montage(trainI[trainYb[:,0]==1][0:50]), cmap='gray', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.imshow(image_montage(trainI[trainYb[:,1]==1][0:50]), cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9P7W_1qGb-9"
   },
   "source": [
    "接下来我们将从训练数据中划分训练集与验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yYF1JxDJGb-9",
    "outputId": "87002b91-27ad-4ce1-e7ea-80ae33f9deb8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate fixed validation set of 10% of the training set\n",
    "vtrainI, validI, vtrainYb, validYb = \\\n",
    "  model_selection.train_test_split(trainI, trainYb,\n",
    "  train_size=0.9, test_size=0.1, random_state=4488)\n",
    "\n",
    "# make validation data\n",
    "validsetI = (validI, validYb)\n",
    "\n",
    "print(vtrainI.shape)\n",
    "print(validI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ps5Fn9yGb-9"
   },
   "outputs": [],
   "source": [
    "# 画图\n",
    "def plot_history(history):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.plot(history.history['loss'], 'r', label=\"training loss ({:.6f})\".format(history.history['loss'][-1]))\n",
    "    ax1.plot(history.history['val_loss'], 'r--', label=\"validation loss ({:.6f})\".format(history.history['val_loss'][-1]))\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xlabel('iteration')\n",
    "    ax1.legend(loc=\"best\", fontsize=9)\n",
    "    ax1.set_ylabel('loss', color='r')\n",
    "    ax1.tick_params('y', colors='r')\n",
    "\n",
    "    if 'accuracy' in history.history:\n",
    "        ax2 = ax1.twinx()\n",
    "\n",
    "        ax2.plot(history.history['accuracy'], 'b', label=\"training acc ({:.4f})\".format(history.history['accuracy'][-1]))\n",
    "        ax2.plot(history.history['val_accuracy'], 'b--', label=\"validation acc ({:.4f})\".format(history.history['val_accuracy'][-1]))\n",
    "\n",
    "        ax2.legend(loc=\"best\", fontsize=9)\n",
    "        ax2.set_ylabel('acc', color='b')\n",
    "        ax2.tick_params('y', colors='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_o0mezhhMCOE"
   },
   "outputs": [],
   "source": [
    "# 早停机制\n",
    "class EarlyStopping:\n",
    "    def __init__(self, monitor='val_accuracy', min_delta=0.0001, patience=5, verbose=1, mode='auto'):\n",
    "        self.monitor = monitor                         # use validation accuracy for stopping\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print(f\"early stopping\")\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elTo1XrvPcPr"
   },
   "source": [
    " Convert history to match original format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuMdbxcnPciW"
   },
   "outputs": [],
   "source": [
    "# Convert history to match original format\n",
    "class HistoryWrapper:\n",
    "    def __init__(self, history_dict):\n",
    "        self.history = history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2v0k-ESQGRo"
   },
   "outputs": [],
   "source": [
    "# 基础配置\n",
    "batch_size = 50\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载器\n",
    "train_dataset = TensorDataset(vtrainI, vtrainYb)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataset = TensorDataset(validI, validYb)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bKyn9PaGb-9"
   },
   "source": [
    "# 逻辑回归\n",
    "- 现在我们尝试使用Pytorch训练一个简单的逻辑回归分类器。由于输入是图像，我们将首先使用“Flatten”层将输入图像转换为向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "4t9mtGwVJyu5",
    "outputId": "958a545d-dd7f-47e0-cf39-bc2a34599c33"
   },
   "outputs": [],
   "source": [
    "# initialize random seed\n",
    "torch.manual_seed(4487)\n",
    "random.seed(4487)\n",
    "\n",
    "# build the network for logistic regression\n",
    "nn_model = nn.Sequential(\n",
    "    nn.Flatten(),                                     # vectorize the input image\n",
    "    nn.Linear(19*19*1, 2),                           # classification layer (2 classes)\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# early stopping criteria\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=5, verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]\n",
    "\n",
    "# compile and fit the network\n",
    "criterion = nn.CrossEntropyLoss()                     # categorical_crossentropy equivalent\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=0.05, momentum=0.9, nesterov=True)\n",
    "                                                      # also calculate accuracy during training\n",
    "\n",
    "history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    nn_model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = nn_model(batch_x)\n",
    "        loss = criterion(outputs, torch.argmax(batch_y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += batch_y.size(0)\n",
    "        train_correct += (predicted == torch.argmax(batch_y, dim=1)).sum().item()\n",
    "\n",
    "    # Validation phase\n",
    "    nn_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in valid_loader:\n",
    "            outputs = nn_model(batch_x)\n",
    "            loss = criterion(outputs, torch.argmax(batch_y, dim=1))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += batch_y.size(0)\n",
    "            val_correct += (predicted == torch.argmax(batch_y, dim=1)).sum().item()\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(valid_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    # Store history\n",
    "    history['loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['accuracy'].append(train_acc)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "\n",
    "    # Early stopping check\n",
    "    earlystop(val_acc)\n",
    "    if earlystop.early_stop:\n",
    "        break\n",
    "\n",
    "\n",
    "history = HistoryWrapper(history)\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Prediction\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_outputs = nn_model(testI)                    # verbose=False equivalent\n",
    "    predY = torch.argmax(pred_outputs, dim=1).numpy()\n",
    "\n",
    "acc = metrics.accuracy_score(testY, predY)\n",
    "print(\"test accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcDPcVnnGb--"
   },
   "source": [
    "## 2. 使用 CNN 进行检测\n",
    "\n",
    "训练一个 CNN 来判断图像小块是否为人脸。使用 `vtrainI` 和 `vtrainYb` 作为训练集，`validsetI` 作为验证集。你可以尝试不同的网络结构，并调整学习率、迭代次数、早停、正则化等超参数以获得更好的结果。为了加快训练，建议使用较大的批量（例如 50）。记得加入“回调”（如早停）以便监控训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnGugDWOGb--"
   },
   "outputs": [],
   "source": [
    "# 构建并训练一个用于 19x19 灰度图的 CNN（不使用数据增强）\n",
    "# 复用上文 DataLoader: train_loader/valid_loader（基于 vtrainI/validI）\n",
    "\n",
    "torch.manual_seed(4487)\n",
    "random.seed(4487)\n",
    "\n",
    "class CNN19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # (N,16,19,19)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                              # (N,16,9,9)\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # (N,32,9,9)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                              # (N,32,4,4)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                 # 32*4*4=512\n",
    "            nn.Linear(32*4*4, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 2)             # 输出 logits，配合 CrossEntropyLoss 使用\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "cnn_model = CNN19()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=1e-3)\n",
    "\n",
    "# 早停（基于验证准确率）\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=1e-4, patience=6, verbose=1, mode='auto')\n",
    "\n",
    "# 记录训练曲线\n",
    "history = {\"loss\": [], \"val_loss\": [], \"accuracy\": [], \"val_accuracy\": []}\n",
    "\n",
    "best_val_acc = -1\n",
    "best_state = None\n",
    "\n",
    "# 训练轮次（可根据需要调整）\n",
    "epochs_cnn = 50\n",
    "for epoch in range(epochs_cnn):\n",
    "    cnn_model.train()\n",
    "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "\n",
    "    for bx, byb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = cnn_model(bx)\n",
    "        target = torch.argmax(byb, dim=1)  # one-hot -> 索引\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        pred = torch.argmax(logits.detach(), dim=1)\n",
    "        train_total += byb.size(0)\n",
    "        train_correct += (pred == target).sum().item()\n",
    "\n",
    "    # 验证\n",
    "    cnn_model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for bx, byb in valid_loader:\n",
    "            logits = cnn_model(bx)\n",
    "            target = torch.argmax(byb, dim=1)\n",
    "            loss = criterion(logits, target)\n",
    "            val_loss += loss.item()\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            val_total += byb.size(0)\n",
    "            val_correct += (pred == target).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / max(1, len(train_loader))\n",
    "    avg_val_loss = val_loss / max(1, len(valid_loader))\n",
    "    train_acc = train_correct / max(1, train_total)\n",
    "    val_acc = val_correct / max(1, val_total)\n",
    "\n",
    "    history['loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['accuracy'].append(train_acc)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "\n",
    "    # 保留最佳模型参数\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = {k: v.cpu().clone() for k, v in cnn_model.state_dict().items()}\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs_cnn} - loss: {avg_train_loss:.4f} - acc: {train_acc:.4f} - val_loss: {avg_val_loss:.4f} - val_acc: {val_acc:.4f}\")\n",
    "\n",
    "    # 早停\n",
    "    earlystop(val_acc)\n",
    "    if earlystop.early_stop:\n",
    "        break\n",
    "\n",
    "# 恢复最佳权重\n",
    "if best_state is not None:\n",
    "    cnn_model.load_state_dict(best_state)\n",
    "\n",
    "# 兼容绘图\n",
    "history = HistoryWrapper(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUIWPHmtGb--"
   },
   "outputs": [],
   "source": [
    "# 可视化 CNN 训练过程\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbfU8drMGb--"
   },
   "outputs": [],
   "source": [
    "# 在测试集上评估 CNN\n",
    "cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = cnn_model(testI)\n",
    "    predY_cnn = torch.argmax(logits, dim=1).numpy()\n",
    "\n",
    "acc_cnn = metrics.accuracy_score(testY, predY_cnn)\n",
    "print(\"test accuracy (CNN):\", acc_cnn)\n",
    "\n",
    "# 可选：混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(testY, predY_cnn)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnwF4C0E9NjA"
   },
   "outputs": [],
   "source": [
    "# 随机展示若干预测样例\n",
    "import numpy as np\n",
    "nshow = 6\n",
    "idx = np.random.choice(len(testI), size=nshow, replace=False)\n",
    "\n",
    "plt.figure(figsize=(9,3))\n",
    "for i, k in enumerate(idx):\n",
    "    plt.subplot(1, nshow, i+1)\n",
    "    plt.imshow(squeeze(testI[k]), cmap='gray', interpolation='nearest')\n",
    "    plt.title(f\"gt:{testY[k]} pred:{predY_cnn[k]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NAAED3WGb-_"
   },
   "source": [
    "_How does the MLP compare to the linear and non-linear classifiers that you tried in Tutorial 4?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxklmpqiGb-_"
   },
   "source": [
    "## 3. Data Augmentation\n",
    "\n",
    "Now use data augmentation (introduced in the last tutorial) to try to improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxcefJzxGb-_"
   },
   "source": [
    "We can also add per-pixel noise or transformations. We define a few functions for adding per-pixel noise.  The following functions will add Gaussian pixel noise, add corruption noise (setting some input pixels to 0), scale and shift pixel values (changing contrast and brightness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPYUjwqhGb-_"
   },
   "outputs": [],
   "source": [
    "def add_gauss_noise(X, sigma2=0.05):\n",
    "    # add Gaussian noise with zero mean, and variance sigma2\n",
    "    X = X.float()\n",
    "    noise = torch.normal(0, sigma2, X.shape, dtype=torch.float32, device=X.device)\n",
    "    return (X + noise).float()\n",
    "\n",
    "def add_corrupt_noise(X, p=0.1):\n",
    "    # apply pixel corruption (zero out value) with probability p\n",
    "    X = X.float()\n",
    "    mask = torch.rand(X.shape, dtype=torch.float32, device=X.device) > p\n",
    "    return (X * mask.float()).float()\n",
    "\n",
    "def add_scale_shift(X, sigma2=0.1, alpha2=0.2):\n",
    "    # randomly scale and shift the pixel values (same for each image)\n",
    "    # Xnew = a X + b\n",
    "    # a is sampled from a Gaussian with mean 1, and variance sigma2\n",
    "    # b is sampled from a Gaussian with mean 0, and variance alpha2\n",
    "    X = X.float()\n",
    "\n",
    "    if X.ndim == 3:\n",
    "        dshape = (X.shape[0], 1, 1)\n",
    "    elif X.ndim == 4:\n",
    "        dshape = (X.shape[0], 1, 1, 1)\n",
    "    else:\n",
    "        dshape = (1,)\n",
    "\n",
    "    a = torch.normal(1, sigma2, dshape, dtype=torch.float32, device=X.device)\n",
    "    b = torch.normal(0, alpha2, dshape, dtype=torch.float32, device=X.device)\n",
    "\n",
    "    result = torch.clamp(a * X + b, 0.0, 1.0)\n",
    "    return result.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNw3_rHcGb-_"
   },
   "source": [
    "Next, we define a function for adding per-pixel noise (in this case just Gaussian noise). The noise is included using the `transforms.Compose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvcQCSh-Gb-_"
   },
   "outputs": [],
   "source": [
    "# build the noise function\n",
    "def addNoise(X):\n",
    "    return add_gauss_noise(X, 0.04)\n",
    "\n",
    "# build the data augmenter\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "\n",
    "    # Random rotation within ±10 degrees\n",
    "    transforms.RandomRotation(10),\n",
    "\n",
    "    # Random horizontal flipping\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "\n",
    "    # Random affine transformation for width/height shift and shear\n",
    "    transforms.RandomAffine(\n",
    "        degrees=0,  # No additional rotation (already handled by RandomRotation)\n",
    "        translate=(0.05, 0.05),  # Width and height shift (5% of image size)\n",
    "        shear=5  # Shearing within ±5 degrees\n",
    "    ),\n",
    "\n",
    "    # Random zooming (simulated using RandomResizedCrop)\n",
    "    transforms.RandomResizedCrop(size=(19, 19), scale=(0.95, 1.05)),  # Adjust size if needed\n",
    "\n",
    "    # Convert PIL image to PyTorch tensor\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # Add custom noise\n",
    "    transforms.Lambda(addNoise)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RivPSjpMGb-_"
   },
   "source": [
    "Next we can show some examples of augmented images. Run the code below to see different random augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "sd5e_YDEGb_I",
    "outputId": "b8de493e-238f-44a0-f677-bfedb1cd01a2"
   },
   "outputs": [],
   "source": [
    "img = trainI[4]\n",
    "imgs = [img[0].detach().numpy()]\n",
    "\n",
    "cnt = 0\n",
    "while cnt < 5:\n",
    "    # Apply augmentation - img already has correct shape (1, 19, 19)\n",
    "    augmented = transform(img)\n",
    "\n",
    "    # Convert to numpy for display (remove channel dimension)\n",
    "    augmented_np = augmented[0].detach().numpy()\n",
    "\n",
    "    imgs.append(augmented_np)\n",
    "    cnt += 1\n",
    "\n",
    "titles = ['original image', 'augmented', 'augmented', 'augmented', 'augmented', 'augmented']\n",
    "plt.figure(figsize=(8,6))\n",
    "show_imgs(imgs, nc=3, titles=titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdIfjJMJGb_J"
   },
   "source": [
    "The augmented images look similar to the original image, but contain small differences that the network can use to learn more about the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5EL28dWGb_J"
   },
   "source": [
    "Now let's try training logistic regression with data augmentation.  We also disable early stopping so that the training sees more augmented data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94KxIZOwsg3t"
   },
   "source": [
    "Customize dataset for augmentation and set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqREwm_ksOjd"
   },
   "outputs": [],
   "source": [
    "class AugmentedTensorDataset(TensorDataset):\n",
    "    def __init__(self, *tensors, transform=None):\n",
    "        super().__init__(*tensors)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.tensors[0][index]\n",
    "        label = self.tensors[1][index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "steps_per_epoch = len(vtrainI)/batch_size\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = AugmentedTensorDataset(trainI, trainYb, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataset = TensorDataset(validI, validYb)       # specify the validation set\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lin699bCoFdK",
    "outputId": "56047953-df91-45ec-f2bd-15e43e87f6bb"
   },
   "outputs": [],
   "source": [
    "# 使用逻辑回归 + 数据增强进行基线训练（保留原实现）\n",
    "# 提示：对于 CrossEntropyLoss，一般不需要在模型中显式加入 Softmax，\n",
    "# 但此处保留原写法以不改变逻辑；你也可以尝试去掉 Softmax 观察效果差异。\n",
    "\n",
    "torch.manual_seed(4487)\n",
    "random.seed(4487)\n",
    "\n",
    "# 构建逻辑回归网络\n",
    "nn_model = nn.Sequential(\n",
    "    nn.Flatten(),                                     # 将输入图像展平为向量\n",
    "    nn.Linear(19*19*1, 2),                           # 分类层（2 类）\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# 编译并训练\n",
    "criterion = nn.CrossEntropyLoss()                     # 等价于分类交叉熵\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=0.05, momentum=0.9, nesterov=True)\n",
    "\n",
    "history = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 训练阶段\n",
    "    nn_model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = nn_model(batch_x)\n",
    "        loss = criterion(outputs, torch.argmax(batch_y, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += batch_y.size(0)\n",
    "        train_correct += (predicted == torch.argmax(batch_y, dim=1)).sum().item()\n",
    "\n",
    "    # 验证阶段\n",
    "    nn_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in valid_loader:\n",
    "            outputs = nn_model(batch_x)\n",
    "            loss = criterion(outputs, torch.argmax(batch_y, dim=1))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += batch_y.size(0)\n",
    "            val_correct += (predicted == torch.argmax(batch_y, dim=1)).sum().item()\n",
    "\n",
    "    # 计算指标\n",
    "    avg_train_loss = train_loss/len(train_loader)\n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    # 记录历史\n",
    "    history['loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['accuracy'].append(train_acc)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs} - '\n",
    "          f'loss: {avg_train_loss:.4f} - '\n",
    "          f'accuracy: {train_acc:.4f} - '\n",
    "          f'val_loss: {avg_val_loss:.4f} - '\n",
    "          f'val_accuracy: {val_acc:.4f}')\n",
    "\n",
    "history = HistoryWrapper(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "8vx89YLYoU5R",
    "outputId": "c41a1b94-2518-42d3-a7d2-731b9f217a43"
   },
   "outputs": [],
   "source": [
    "# 可视化曲线 + 在测试集上评估（逻辑回归 + 数据增强）\n",
    "plot_history(history)\n",
    "\n",
    "# 预测\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_outputs = nn_model(testI)\n",
    "    predY = torch.argmax(pred_outputs, dim=1).numpy()\n",
    "\n",
    "acc = metrics.accuracy_score(testY, predY)\n",
    "print(\"test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4R6xnjeGb_J"
   },
   "source": [
    "使用数据增强后，测试集准确率从 0.60 提升到了 0.70！（你的结果可能会有所不同）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rl9G3AhLGb_J"
   },
   "source": [
    "现在请在上一节中效果最好的 CNN 基础上，结合数据增强进行训练。\n",
    "尝试不同的逐像素噪声强度，以及不同的 transforms 配置和它们的组合，看看是否能进一步提升准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PFaA0kZGb_J"
   },
   "outputs": [],
   "source": [
    "# 训练：使用上一节里表现最好的 CNN，并结合数据增强\n",
    "# 注意：这里我们覆盖 nn_model，使得后续推理（例如滑窗检测）使用该 CNN。\n",
    "\n",
    "# 固定随机种子，便于复现实验\n",
    "torch.manual_seed(4487)\n",
    "random.seed(4487)\n",
    "\n",
    "# 定义一个适用于 19x19 灰度图的小型 CNN\n",
    "class BestCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # 输入: (N, 1, 19, 19)\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # -> (N,16,19,19)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                              # -> (N,16,9,9)\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # -> (N,32,9,9)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                              # -> (N,32,4,4)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                 # -> (N, 32*4*4=512)\n",
    "            nn.Linear(32*4*4, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 2)             # 输出 logits（不要加 Softmax，CrossEntropyLoss 内部已包含）\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 使用数据增强的数据加载器（在前文 AugmentedTensorDataset 里已构建 train_loader/valid_loader）\n",
    "# train_loader: 使用 transform=transform 的增强\n",
    "# valid_loader: 不做增强，仅评估\n",
    "\n",
    "nn_model = BestCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr=1e-3)\n",
    "\n",
    "# 早停（复用之前实现的 EarlyStopping）\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=1e-4, patience=6, verbose=1, mode='auto')\n",
    "\n",
    "history = {\"loss\": [], \"accuracy\": [], \"val_loss\": [], \"val_accuracy\": []}\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    # 训练\n",
    "    nn_model.train()\n",
    "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "    for batch_x, batch_yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = nn_model(batch_x)\n",
    "        target = torch.argmax(batch_yb, dim=1)  # one-hot -> 类别索引\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        pred = torch.argmax(logits.detach(), dim=1)\n",
    "        train_total += batch_yb.size(0)\n",
    "        train_correct += (pred == target).sum().item()\n",
    "\n",
    "    # 验证\n",
    "    nn_model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_yb in valid_loader:\n",
    "            logits = nn_model(batch_x)\n",
    "            target = torch.argmax(batch_yb, dim=1)\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            val_total += batch_yb.size(0)\n",
    "            val_correct += (pred == target).sum().item()\n",
    "\n",
    "    # 记录指标\n",
    "    avg_train_loss = train_loss / max(1, len(train_loader))\n",
    "    avg_val_loss = val_loss / max(1, len(valid_loader))\n",
    "    train_acc = train_correct / max(1, train_total)\n",
    "    val_acc = val_correct / max(1, val_total)\n",
    "\n",
    "    history['loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['accuracy'].append(train_acc)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - loss: {avg_train_loss:.4f} - accuracy: {train_acc:.4f} - val_loss: {avg_val_loss:.4f} - val_accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # 早停检查\n",
    "    earlystop(val_acc)\n",
    "    if earlystop.early_stop:\n",
    "        break\n",
    "\n",
    "# 兼容上面的 plot_history(history)\n",
    "history = HistoryWrapper(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdIVGpc7Gb_K"
   },
   "outputs": [],
   "source": [
    "# 可视化训练过程（数据增强 + 最佳 CNN）\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eig1OLVsGb_K"
   },
   "outputs": [],
   "source": [
    "# 在测试集上评估（使用数据增强训练得到的最佳 CNN）\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_test = nn_model(testI)\n",
    "    predY = torch.argmax(logits_test, dim=1).numpy()\n",
    "\n",
    "acc = metrics.accuracy_score(testY, predY)\n",
    "print(\"test accuracy (CNN + augmentation):\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTfL2TTFGb_M"
   },
   "outputs": [],
   "source": [
    "# 额外：查看混淆矩阵与分类报告\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(testY, predY)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\", classification_report(testY, predY, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jc0I1L3pGb_M"
   },
   "source": [
    "# 测试图像\n",
    "现在我们来在真实图像上尝试人脸检测。下载 \"nasa-small.png\" 并放在与你的 ipynb 文件相同的目录下。下面的代码会加载图像、裁剪滑动窗口补丁并提取特征。（这一步可能需要几分钟）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-nJm4MJGb_M"
   },
   "outputs": [],
   "source": [
    "fname = \"nasa-small.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "8qpf4lkyGb_M",
    "outputId": "0ceaee3f-25f5-4055-d4d9-929a54e83dea"
   },
   "outputs": [],
   "source": [
    "# load image\n",
    "testimg = skimage.io.imread(fname, as_gray=True)\n",
    "print(testimg.shape)\n",
    "plt.imshow(testimg, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfeOfGMOGb_M",
    "outputId": "5addda07-ac46-47e2-a250-b8177a833271"
   },
   "outputs": [],
   "source": [
    "# step size for the sliding window\n",
    "step = 4\n",
    "\n",
    "# extract window patches with step size of 4\n",
    "patches = skimage.util.view_as_windows(testimg, (19,19), step=step)\n",
    "psize = patches.shape\n",
    "# collapse the first 2 dimensions\n",
    "patches2 = patches.reshape((psize[0]*psize[1], psize[2], psize[3], 1))\n",
    "print(patches2.shape)\n",
    "\n",
    "# histogram equalize patches (improves contrast)\n",
    "#newI = empty(patches2.shape)\n",
    "#for i in range(patches2.shape[0]):\n",
    "#    newI[i,:,:] = skimage.exposure.equalize_hist(patches2[i,:,:])\n",
    "newI = patches2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcyx5I6MGb_M"
   },
   "source": [
    "现在使用你的分类器进行预测。已经提取好的小图块保存在 `newI` 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVyB5pHuGb_M"
   },
   "outputs": [],
   "source": [
    "# 使用你上面训练好的分类器（nn_model）对 newI 的窗口进行预测\n",
    "# 注意：nn_model 现在是“数据增强 + 最佳 CNN”训练得到的模型\n",
    "\n",
    "patches_tensor = torch.FloatTensor(patches2.transpose(0, 3, 1, 2))  # (N, H, W, C)->(N, C, H, W)\n",
    "with torch.no_grad():\n",
    "    outputs = nn_model(patches_tensor)\n",
    "    prednewY = torch.argmax(outputs, dim=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "w0O_gOkMGb_N"
   },
   "source": [
    "接下来我们将在图像上可视化结果。使用下方代码进行显示。`prednewY` 是预测结果向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "id": "-Zy7pBucGb_N",
    "outputId": "993abaa3-dbda-47b3-c117-4affa68bba57"
   },
   "outputs": [],
   "source": [
    "# reshape prediction to an image\n",
    "imgY = prednewY.reshape(psize[0], psize[1])\n",
    "\n",
    "# zoom back to image size\n",
    "imgY2 = ndimage.interpolation.zoom(imgY, step, output=None, order=0)\n",
    "# pad the top and left with half the window size\n",
    "imgY2 = vstack((zeros((9, imgY2.shape[1])), imgY2))\n",
    "imgY2 = hstack((zeros((imgY2.shape[0],9)), imgY2))\n",
    "# pad right and bottom to same size as image\n",
    "if (imgY2.shape[0] != testimg.shape[0]):\n",
    "    imgY2 = vstack((imgY2, zeros((testimg.shape[0]-imgY2.shape[0], imgY2.shape[1]))))\n",
    "if (imgY2.shape[1] != testimg.shape[1]):\n",
    "    imgY2 = hstack((imgY2, zeros((imgY2.shape[0],testimg.shape[1]-imgY2.shape[1]))))\n",
    "\n",
    "# show detections with image\n",
    "#detimg = dstack(((0.5*imgY2+0.5)*testimg, 0.5*testimg, 0.5*testimg))\n",
    "nimgY2 = 1-imgY2\n",
    "tmp = nimgY2*testimg\n",
    "detimg = dstack((imgY2+tmp, tmp, tmp))\n",
    "\n",
    "# show it!\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(imgY2, interpolation='nearest')\n",
    "plt.title('detection map')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(detimg)\n",
    "plt.title('image')\n",
    "plt.axis('image')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
